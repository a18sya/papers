\documentclass{article}
\usepackage{CJKutf8}
\usepackage{multicol}
% Packages
\usepackage{lipsum} % For generating dummy text
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{hyperref}
\usepackage{pgfplots}
\usepackage{caption}
\captionsetup{font=small}
\usepackage{standalone}
\usepackage{listings}
\usepackage{xcolor} % For setting colors
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{afterpage}
\usepackage{placeins}
\usepackage{tikz}

\lstset{
  language=[LaTeX]TeX,
  breaklines=true,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue},
  commentstyle=\color{green},
  backgroundcolor=\color{gray!10},
  frame=single,
  showspaces=false,
  showstringspaces=false,
}
\pgfplotsset{compat=1.17} % Use this to ensure compatibility with newer features
\setlength{\parskip}{6pt}
% Title and author
\title{Autonomous competence identification protocol}

\author{Tim Pechersky}


\begin{document}
\begin{CJK}{UTF8}{gbsn}

	% \twocolumn
	\maketitle


	\begin{abstract}
		This paper proposes a novel protocol for designing ranking systems applicable to consensus-building protocols and decentralized autonomous organizations (DAOs). Leveraging recent cryptographic advancements and social science insights, the protocol facilitates autonomous decision-making in trustless environments based on agent interactions, addressing key challenges in autonomous organizations. We examine an existing precedent, originating as an easy-to-understand tabletop game, which demonstrates promising participation rates even among non-technical users. Our proposed implementations focus on defining interoperable and liquid voting weights for participants, facilitated in both computational and non-computational (social) networks. Additionally, we briefly review economic models for the practical utilization of such competence frameworks and game theoretic moments.

	\end{abstract}
	\begin{multicols}{2}

		\section{Introduction}

		The quest for consensus, a cornerstone of collective decision-making, has deep historical roots. From the ancient Chinese concept of \textit{zhongyong} {\CJKfamily{bsmi}
			中庸}, advocating for moderation and balance in governance, to the Roman Republic's emphasis on \textit{senatus consulta} (senate decrees) reached through deliberation and compromise, societies have long grappled with the challenge of aligning diverse perspectives towards a common goal. The study of these historical precedents continues to inform modern approaches to consensus \cite{Andersen2019} \cite{Frederic2014}. \\
		The pursuit of consensus, has gained renewed significance in the digital age. Originating from the Bitcoin whitepaper \cite{Satoshi}, blockchain technology fundamentally seeks consensus and establishes trustless systems through cryptographic signatures. While significant progress has been made in developing efficient Byzantine Fault Tolerance (BFT) algorithms for reaching consensus on verifiable data \cite{Genrui2023}, the challenge of achieving consensus on subjective or non-deterministic matters within DAOs \cite{Hassan2021} remains a complex issue \cite{Shuai2019}\cite{Rainer2023}. This has led some researchers to question the ability of autonomous organizations to overcome the hierarchical issues present in today's society \cite{Marcella2016} \cite{Xuan2024}.   \\
		This paper addresses the gap between formally verifiable, automated consensus and subjective human decision-making. We propose a protocol that can achieve consensus even for subjective matters by qualifying participants based on their ability to represent a group's interests and intents. This protocol aims to provide a foundational building block for designing ranking systems applicable to both computational and social networks, and capable to address some of long standing governance issues such as agenda manipulation \cite{McKelvey1976} problem.\\
		Main objectives thus are to propose a methodology for creating a ranking system in a trustless environment, review attack vectors and resistance mechanisms, provide a case study of existing use-case and discuss potential economic models for the practical utilization of such competence frameworks.
		We begin by reviewing existing consensus mechanisms and their limitations, focusing on DAOs and their governance mechanisms. We then introduce our proposed protocol, followed by a discussion of its implementation and potential economic models. Finally, we present a case study of an existing use case and conclude with a discussion of future research directions.\\

		\section{Background}
		% Write your methodology here
		Decentralized Autonomous governance nor consensus protocols cannot be defined completely trough cyber-physical systems \cite{Lee2008} methodology. Nevertheless, an end goal for any autonomous governance is to operate CPS. In this context any kind of IT governance system can be seen trough methodology of Cyber-Physical-Social-System (CPSS) \cite{Fei2016}.


		Studies of management perspectives in cyber age introduce parallel management \cite{Wang2022} ideas, management frameworks proposed to model DAOs as CPSS openly discuss need for multidimensional indexes and foundational models \cite{Juanjuan2023}. In order to support such grand design ambition, the DAO organizations must be able to show other metrics of their governance to provide the best possible performance. Additionally, as discussion for parallel management \cite{Wang2022}, there is a need for a robust mechanism for reinforcing the informational and intellectual capabilities of organizations, enabling them effectively benchmark performance of AI enabled agents against human in various tasks and aspects of governance and management.

		In order to support quantities analysis of decentralization metric, Nakamoto Coefficient\cite{Balaji2017} was proposed, defined as \textit{how many entities one would need to to be compromised to control entire system} it can be used as decentralization criteria.

		Besides these new concepts, the traditional governance models long standing problems, such as agenda manipulation \cite{McKelvey1976} that should be addressed well to ensure high reliability of organizations in autonomous systems.


		\subsection{Consensus Layer}
		Blockchain is a distributed and decentralized network that follows some particular consensus protocol in order to maintain continuous sequence, chain of blocks\cite{Merlinda2019}, where each new block consists of a digital records to a united ledger book. First introduced at launch of Bitcoin\cite{Satoshi}, since then grown to an industry where multiple approaches and protocols were developed and initial ability to write a records in to ledger book was elaborated to ability to write code in ledger records such that can change states of book itself.
		The blockchain governance plays a critical role in any blockchain protocol and can be summarized as consisting of Validators, Users, Governance Mechanisms and core developer community; In this context blockchain network is analogous to an organization, consisting validators (employees), protocols and governance structure whose activity result in services provided to users that also have to say their word by paying for using the protocol.

		The contrast between traditional organization and blockchain governance is CSP friendly automation. Such are designed to follow some determined rules of maintaining distributed ledger with no need for human stakeholder decision for a regular operations which are automated by running specific software applications (nodes) that act on behalf of stakeholder.
		These however work only well up to the point when the protocol changes are desired or some vulnerability happens which leads to stakeholder collective decision for stepping-off the protocol rules \cite{Liu2021} for at least one block. Such occasions generally are called hard-forks and have specifics that coordinated consensus between node operators changes their protocol rules to move away from existing logic. The "fork" in context describes split of consensus in two possible ledger book states which are not compatible. \\
		Consensus layer protocols also have the underlying node operator community which incentive driven and studies on Nash Equilibrium \cite{Nida2020} are done while the real situation for Ethereum is that Miner Extracted Value is shown \cite{Philip2019} as realistic thread to protocol level security that comes down to affecting applications such as decentralized exchanges. Same paper also observes that agents pursuing MEV can achieve cooperative equilibrium in terms of priority gas auctions. \\
		"Ethereum Proof-of-Stake Consensus Layer: Participation and Decentralization research" \cite{Dominic2023} has shown that practical Nakamoto coefficient numbers in automated consensus engines such as PoS and Pow (Proof of Stake and Work accordingly) have stabilized on a very low numbers of less then 5 entities standing behind whole pool of validators and miners, and seem not to show any positive dynamics.

		% \paragraph{}
		\subsection{Application Layer}
		While research in CPSS field point out demand for DAOs as solution \cite{Fei2016}\cite{Wang2022}\cite{Juanjuan2023}, the ability of DAOs to perform well and be competitive, however, is under question, as many researchers point out associated problems \cite{Rainer2023}\cite{Marcella2016}\cite{Xuan2024}.  \\An empirical Study of On-Chain Governance conducted by Rainer Feichtinger et. al. \cite{Rainer2023} shows low Nakamoto coefficient numbers, however comparing it with Consensus Layer research \cite{Dominic2023} we can conclude there is a positive dynamic in the Nakamoto coefficient over time in DAOs, compared with absence of such for the consensus layer. Same research\cite{Rainer2023} also shown that analyzed DAOs Gini coefficients\cite{Lidia2012} are high, reaching 0.888-1 for direct holders and 0.667-0.980 range when counting delegates, also shown participation rate in DAOs are low. Out of four analyzed DAOs (Compound, Uniswap, ENS and Gitcoin), none of them are showing positive dynamics in participation rate over time, and mean numbers for participation even amongst delegates are in range of 1.1-9.9\% of total delegated accounts.


		Another highlighted problem can be seen in the voting participation quorum thresholds, which are low. For example, Compound DAO quorum requires only 400,000 \cite{CompDAO} votes out of 10,00,000 total token supply \cite{CompToken}, which is only 4\%, yet in practice some of proposals fail to reach even this low threshold from the first time and have to re-submit \cite{CompProp232}\cite{CompProp237}. To illustrate problem further quorum requirements of few high value DAOs are illustrated in Table \ref*{table:dao-metrics}. Ethereum PoS validator count is also shown to represent a consensus level engine specifics. Such low quorum requirements are directly explainable by a low participation rates, and already have a record of quorum attacks \cite{AragonBlog}\cite{rhizoo2023} precedents, that were exploiting this weakness, while contrary in high participation rate consensus layer systems, such as PoS and PoW, the financial incentives towards participation shown not just to negatively impact  Nakamoto coefficients, but also have shown that any network node must be seen as rational-agent which may diverge from collective interest \cite{Philip2019}, yet even with that, the technical complexity and network requirements result in only 19\% effective quorum attack threshold for whole Ethereum L1 at the time of writing.
		% \end{multicols}
		% \afterpage{
		% \onecolumn
		% \clearpage
		\input{quorums.tex}
		% }
		% \begin{multicols}{2}
		% \twocolumn
		% \paragraph{}
		\subsection{Comparing two above}
		DAOs ultimately are just an abstraction layer on top of Consensus, allowing blockchain users to abstract away from calculations intensity onto smart contract programming and therefore more versatile, dynamic governance systems that can rely on underlying consensus security guarantees. Difference however also lies in implementation specifics: while Consensus layers do provide participation incentives, the application layer organization might not propose such at all, instead providing a means to make a governance decisions that are profitable on their own. \\ Analyzing  Nakamoto coefficient we can see a notable difference between Nakamoto coefficient in DAOs vs Consensus layer. One possible explanation for this phenomenon can be coined as "curse of money making money". It suggests that in order to ensure growth of Nakamoto coefficient, the ability to influence the system should grow at a rate that must be sub-linear in relation to entities efforts (investments), ensuring that no disproportionate compounding of power occurs. In other words, the growth of influence should not match nor exceed a linear rate to prevent centralization, highlighting the necessity for mechanisms that enforce a diminishing increase in influence relative to investment or contribution (Fig. \ref*{fig:growth-influence}).

		One another notable difference is in the security model. While relying on consensus engine enables security guarantees, the opposite side of that medal is that such application layer governance mechanisms have no similar alternative as consensus layer operators do with hard-fork ability. Even if community members agree on such decision in case exploit happens, there is no easy way to "split away" saving full state. The only known occasion of such successful split was The DAO Hack Hard-fork which was done very controversially at the protocol level.  \cite{Liu2021}.
		This is a substantial difference with consensus layers, where any participation requires a commitment that either requires to do work prior to a particular vote (PoW), or have assets at stake (PoS, Optimistic Rollups) that can be lost during due to any activity by operator against the protocol rules.\\
		Lack of such ongoing commitment mechanisms in the application layer, brings in substantial security risks as governance attacks become less risky for the adversary \cite{AragonBlog}\cite{rhizoo2023}. Such risks led to solutions such as time-locks \cite{Jack2021}, and rage quit \cite{Ameen2019} methods giving individual stakeholders a last-resort options to leave the protocol (arguably) safely at the expense of delayed actions taken by the organizations.

		While these solutions are effective in preventing funds loss, the reduce in reaction time by organization is not always acceptable. Need for prompt decision making is leads to empowering security players to run a privileged multi-signature wallets to run emergency stop or veto power over DAO protocols \cite{Jason2024}. Fact of presence of such, centralizing actors makes DAO frameworks to behave in non-autonomous way. The more general question is left open - how to appoint such privileged actions takers in an autonomous ways, ideally defining the privileges as a function of certainty in the actor?

		% \end{multicols}
		% Manually place the figure without the figure environment
		% Inside the multicol environment

		\begin{figure}[ht]
			\centering
			\begin{minipage}{0.45\textwidth}
				\centering
				\begin{tikzpicture}
					\begin{axis}[
							title={Wealth Distribution Comparison},
							xlabel={Cumulative Share of People},
							ylabel={Cumulative Share of Wealth},
							xmin=0, xmax=1,
							ymin=0, ymax=1,
							legend pos=north west,
							axis lines=middle,
							axis line style=<->,
							x label style={at={(axis description cs:0.5,-0.1)},anchor=north},
							y label style={at={(axis description cs:-0.1,.5)},rotate=90,anchor=south},
							grid=major,
						]
						% Line of Equality
						\addplot[
							color=black,
							mark=none,
							dashed,
							line width=1pt,
							domain=0:1,
						]{x};
						\addlegendentry{Equality}

						% Centralizing Incentives Lorenz Curve
						\addplot[
							color=red,
							mark=none,
							line width=2pt,
							domain=0:1,
							samples=100,
						]{x^2};
						\addlegendentry{Centralizing}

						% Sustainable Incentives Lorenz Curve
						\addplot[
							color=blue,
							mark=none,
							line width=2pt,
							domain=0:1,
							samples=100,
						]{sqrt(x)};
						\addlegendentry{Sustainable}

					\end{axis}
					% Your first plot code here
				\end{tikzpicture}
				\caption{First Plot}
				\label{fig:growth-influence}
			\end{minipage}\hfill
			\begin{minipage}{0.45\textwidth}
				\centering
				\begin{tikzpicture}
					\begin{axis}[
							title={Figure 1: Agent of Influence vs Efforts},
							xlabel={Effort},
							ylabel={Influence in the System},
							xmin=0, xmax=1,
							ymin=0, ymax=1,
							legend pos=north west,
							ymajorgrids=true,
							grid style=dashed,
						]
						% Linear growth
						\addplot[
							color=orange,
							mark=none,
							dashed,
							line width=1pt,
							domain=0:1,
						]{x};
						\addlegendentry{Equilibrium}
						% Sub-linear growth (example: square root)
						\addplot[
							color=red,
							mark=none,
							line width=2pt,
							domain=0:1,
							samples=100,
						]{x+x*(ln(x+1))};
						\addlegendentry{Centralizing}
						\addplot[
							color=blue,
							mark=none,
							line width=2pt,
							domain=0:1,
							samples=100,
						]{{ln(x+1)}};
						\addlegendentry{Sustainable}
					\end{axis}
					% Your second plot code here
				\end{tikzpicture}
				\caption{Second Plot}
			\end{minipage}
		\end{figure}
		% \begin{multicols}{2}

		\subsection{Recent cryptographic advancements}
		Recent cryptographic advancements have enabled the development of new governance and consensus mechanisms that may be used to address the challenges faced by DAOs. For example, the use of zk-SNARKs (Zero-Knowledge Succinct Non-Interactive Argument of Knowledge) allows for the creation of verifiable and private voting systems that can be used to ensure the integrity of voting processes within DAOs \cite{Ben-Sasson2014}, while MPC threshold-signature protocols can be used to create secure multi-party data signing process \cite{Doerner2023} and fully homomorphic encryption promises us soon ability to run fully private calculation directly on-chain \cite{Fhenix}.\\
		Summing this section up, we can say that whatever new protocol is designed for governance, it is realistic to set requirements of privacy in voting and proposing process.

		\subsection{Proposed Protocol origins}\label{sec:protocol_origins}
		The foundation of this research stems from a game played by a small group of Lithuanian friends in a chat messenger since 2017. Initially designed for leisure and sharing music, this game has unexpectedly exhibited properties desirable in governance protocols.\\
		The game, played by 5 to 10 participants, involves a rotating "game master" role. Each round, participants submit music they enjoy to the game master, who compiles them into a playlist. Participants then vote on their favorite composition, and the game master reveals the results, including proposer identities and scores. The game continues until 100 compositions are added to the playlist, with the final ranking based on accumulated scores\cite{DariusYoutube}.\\
		This game's design inherently resists agenda manipulation due to its mandatory proposal-submission prerequisite for voting, a stark contrast to traditional voting systems vulnerable to small-group dominance\cite{McKelvey1976}. Furthermore, it effectively mitigates negative proposal effects like the Halo effect \cite{Verhulst2010}. \\
		Interestingly, the game demonstrates high participation and retention rates, suggesting potential for adaptation as a governance protocol (elaborated in case study section). The primary limitation lies in participants' inclination towards specific interests (music in this case) or groups of people.

		The game's communication complexity appears to be $O(3n)$ per round, as participants submit a proposal, receive a batch of proposals, and then submit a vote.

		This research aims to build upon this foundation, exploring the game's potential as a scalable, decentralized governance protocol with built-in resistance to manipulation and high participant engagement.


		\subsection{Summing up the context}
		From the issues identified in the background sections we can sum up that there are multiple problems that are faced both on network protocol level governance as well as on application layer built DAOs as well: Low participation rates, low Nakamoto coefficients, lack of application layer commitments, and lack of multidimensionality.
		We can also note that incentive based protocols cause centralization, yet decentralized organizations are not able to provide a commitment mechanism for participants, nor do they have truly autonomous way to appoint stakeholders purely from the mission it has, nor identify competent actors in the system to take prompt, time-critical actions.\\
		We have discussed two different kinds of systems so far - based on consensus layer continuous proving and application layer share-holder voting and identified different problems of both of these kinds.
		We also outlined that already existing DAO precedent can show positive dynamics in Nakamoto coefficient when influence is sub-linear to efforts, compared to Consensus Layer systems that incentivize participants. We also outlined precedent of a game that has high participation rates and user retention (further elaborated in case study section).\\

		\section{Protocol Description}

		In order to enable deductive reasoning, we can outline specifications that a generic abstract organization must fulfill. Besides these, we preferably want to system to be compatible with existing solutions and technologies that allow data integrity, privacy and security, assuming that distributed ledger and multiparty computation signing may be combined to cover these problems. \\
		We are seeking for protocol that is:\\
		\textbf{Mission aligned}: Organization members should actively participate in the decision-making process by the design of the protocol, their activity shall be directly impacting the organization goals and mission.\\
		\textbf{Highly performant}: Ideally, every organization design shall automatically align participants in collaborative model, enabling everyone to do their best contribution towards shared direction, with utilizing full potential of competitive performance provided by decentralized autonomous methodology.\\
		\textbf{Centralization resilient}: Protocol should be designed in a way that over time dependency on single actors shall be reduced, Nakamoto coefficient shall increase, promoting collaboration over competition for those aligned in automatic manner. \\
		\textbf{Multidimensionality}: Protocol should enable multidimensional indexes and foundational models to be built on top of it, as well as promote working groups that can be more operative than a main governing body. At the global scale this should support automatically combining multiple DAOs in superset and enable establishing data, asset and control specific flows-controls.\\
		\textbf{Rational}: Protocol should be designed in a way that any network node must be seen as rational-agent which may diverge from collective interest or collude with others and still not able to reach  influence over the system beyond what protocol accounts for.
		\\

		\paragraph*{}
		In order to define quantitative metrics over these declared values in a most generic way, let's introduce the concept of a agent alignment vector, denoted as  $\vec{A}$. This vector captures the collective preference of the group that can be seen as united entity within a given context, such as publicly announced topic, or any other group member specific property. We can denote such context as global alignment vector as:
		\begin{equation}
			\label{eq:glob-align}
			\vec{G} = \sum_{i=0}^{N_{i}} \vec{A_i} + \vec{C}
		\end{equation} Where $N_i$ denotes total number of such groups at given time and $\vec{C}$ is some predefined context constant value.
		If we assume numerous such possible contexts denoted ${N_j}$, then we also can denote an universal alignment vector describing every possible context $j$ as:
		\begin{equation}
			\vec{U} = \sum_{j=0}^{N_{j}} \vec{G_j}
		\end{equation}

		To define a performance criteria, we can denote time dependency for these vectors, to underscore their ever changing nature of decision making:
		\begin{equation}
			\vec{U(t)} = \sum_{j=0}^{N_{j}} \vec{G_j(t)} = \sum_{j=0}^{N_{j}}(\sum_{i=0}^{N_{i}} \vec{A_{ij}(t)} + \vec{C_j})
		\end{equation}
		In such case, a prompt decision making process,  describing ability for high performance can be seen as derivate function of time:
		\begin{equation}
			\frac{d\vec{U}}{dt} = \sum_{j=0}^{N_{j}} \frac{d\vec{G_j}}{dt} = \sum_{j=0}^{N_{j}} (\sum_{i=0}^{N_{i}} \frac{d\vec{A_{ij}}}{dt} + \vec{C_j})
		\end{equation}

		Deducting of our requirements, the mission alignment is can be seen as stability of $\vec{U}(t)$ and $\vec{G_j}(t)$ over time, multidimensionality is quantified by ${N_j}$,  participation rates by $N_i$ while centralization by standard deviation of the magnitudes of a set of vectors $\vec{A_{ij}}(t)$ and can be denoted as follows:

		\begin{equation}
			\sigma_{\|\vec{A_{ij}}(t)\|} = \sqrt{\frac{1}{N_{i}N_{j}} \sum_{j=0}^{N_{j}} \sum_{i=0}^{N_{i}} \left( \|\vec{A_{ij}}(t)\| - \mu \right)^2}
		\end{equation}

		where $\|\vec{A_{ij}}(t)\|$ represents the magnitude of the vector $\vec{A_{ij}}(t)$, and $\mu$ is the mean magnitude of the vectors, given by:

		\begin{equation}
			\mu = \frac{1}{N_{i}N_{j}} \sum_{j=0}^{N_{j}} \sum_{i=0}^{N_{i}} \|\vec{A_{ij}}(t)\|
		\end{equation}

		Assuming that $\vec{A}$ represents groups interest, it can be further broken down as the aggregate of individual preference vectors $\mathbf{P_i}$. In such, a group ideal delegate can be defined as a participant whose $\mathbf{P_i}$ aligns most closely with $\vec{A}$.
		This alignment maximizes their positive contribution to the overall group preference and can be quantified using measures like cosine similarity or Euclidean distance between the participant's and the group's vectors.

		The protocol's inclusive and autonomous requirement nature allows to envision that even a fully stochastic process, where participants could be assumed to make random decisions regarding tournament participation, proposals, and voting, an $\vec{A}$ could be defined.
		However, we postulate the existence of an underlying, unknown global alignment vector $\mathbf{G(t)}$, that reflects the overall preferences of all protocol participants across time. \\
		This concept accommodates the diverse preferences of all participants, even in the boundary case of entirely random decisions.
		In this fully stochastic scenario, the group's alignment is characterized by entropy, a measure of randomness. The Euclidean distance of each member's rank from the most probable rank for a random participant can serve as a measure of their capacity for random decision-making. \\
		Conversely, in non-stochastic processes, participants exhibit alignment towards an arbitrary direction, shaped by their free-will choices to join specific groups and context. The protocol goals hence can be seen as to quantify these vectors and ensure their desired properties.


		\subsection{Transferability}
		\label{sec:transferability}
		In order to support solving all of the objectives, we propose to specify, that outcome of protocol is a transferrable asset, that can effectively tokenize the competence rating of bearer.
		Transferability is an important aspect as this allows free market rules to establish and accomplish multiple goals, starting with agent rational actions: even concepts of corruption and collusion can be seen as game-theoretic \cite{Macrae1982}, are not necessarily bad \cite{Leff1964}, and can be seen trough definition of an intrinsic value of any transferable asset. Other words saying, we see personal competences in CPSS frameworks useful as a market value, that may be useful to trade. \\While this can be argued as a controversial statement, we can discuss that in the real world competence indeed is often traded in form of a investing time and money in education, relationships, that eventually form a social ranking. Since we declare as a requirement to have a compounding resistance, it forms a solid basis for building economic models that penalize competence-market participants heavy enough,  so that competence is not traded in a way that it can be easily bought by a single entity.
		Transferability of value opens vast application opportunities, as other protocols are free to define staking commitments with specific slashing rules, similarly as PoS consensus mechanisms do, therefore bringing one of the lacking consensus layer features on-to on-chain governance. Eventually, this helps forming a rational economic model that would incentivize any participant to treat his rating in a similar careful and responsible manner, as one does with his assets.\\
		With such, we envision that both ${\vec{A}}$ and ${\vec{G}}$ may be tokenized separately, whilst there is connection between these, reciprocity is not a strict requirement, meaning that while conversion of ${\vec{A}}$ into ${\vec{G}}$ must be supported by protocol as per Eq. \ref{eq:glob-align}, the reverse exchange can be left for a free market to decide upon, leaving some extra space for protocol incentives design which we will use in following sections to create additional useful properties for the protocol.
		Nevertheless, transferability does not exclude any applications where such rating asset must be locked. Use cases of ownership within Account Abstraction\cite{Qin2023} model could be designed to ensure asset is non-transferable and acts as account-bond proof of competence if such an use case would be desired.\\

		\subsection{Ranking ladder}

		Providing a resistance to influence compounding becomes a critical aspect part for such protocol, since we are relying to a free-market values and principally do not require any specific identity solution as a dependency to this protocol.
		Our foundational model for this resistance lies in extending  ~\ref{sec:protocol_origins} idea, to introduce \textit{ranking ladder} (Fig. \ref*{fig:game-connection}) that lets game winner to participate in next game with higher level of rewards only if it holds an asset of rank below.Such architecture allows to design initially low ability to influence ${\vec{G}}$ and exponentially increase as participant succeeds climbing up ladder. As participants gain higher ability to influence global alignment value, quantitative measure of that is their individual preference vector magnitude $|P|$, which protocol will account for increasing only as they prove to be the most impactful part of their group $|A_i|$.
		\input{ladder.tex}
		Participant rank $R$ hence represents such quantization of $|A_i|$:

		\begin{equation}
			R = Q(|A_i|)
		\end{equation}
		To further introduce compounding resistance, we define protocol ladder climb event requirement: previous ladder step tokenized element must be removed (exchanged) in order to obtain higher ladder rank.


		In order to see how this affects protocol parameters on practice, we can analyze a sybil attack scenario, which is one of most prominent threads for any permissions less protocol that produces intrinsic value.


		If each game requires a commitment, such as a participation fee, we can demonstrate that the proposed ranking ladder introduces a desired non-linear compounding friction for potential malicious actors attempting to manipulate the system.

		To illustrate this, let's use the concept of a agent alignment vector introduced in Eq.(\ref*{eq:glob-align}). In the absence of collusion or manipulation, a blind proposing-voting process is inherently probabilistic, where the inverse of groups  magnitude $|\vec{A}|$ quantifies the resistance to entropy inherent in participants' choices.


		Any colluding actors attempting a sybil attack are effectively trying to manipulate this global alignment vector $\mathbf{G(t)}$. Given our earlier requirements for an ideal protocol, it should encourage the formation of small groups while maintaining a large overall active participant count. This breakdown into smaller groups serves as a pre-alignment mechanism, as participants willingly choose to collaborate. In this context, any group can be seen as colluding, with sybil attacks representing an extreme case of such alignment.

		Therefore, from the outset, each group is inherently aligned towards a specific direction, determined by the free will of its members to participate in a particular tournament. This pre-alignment introduces a degree of predictability, quantified by $|\vec{A}|$, into an otherwise stochastic process.


		If there is a game fee, that creates participation resistance, we can say that achieving a specific level of competence cost is $\$C$ and can be expressed as a function of level of competence $i$ and game fee $X_g$ and mathematical expectation for costs achieving specific rank via sybil attack described as
			$$\mathbb{E}[\$C(i)] = X_g \cdot \mathbb{E}[N_{\text{sybils}}(i)]$$

			% $$\mathbb{E}[\$C(i)] = X_g*\mathbb{E}[{N_{sybils}(i)}]$$

			Where $N_{sybils}(i)$ is a number of sybil accounts required to win a game of rank $i$. Due to tournament fragmentation, an attacker mixing sybil accounts with fair players must strategically allocate sybils across games for cost efficiency. However, this is challenging due to each group's unique $\vec{A}$, finding suitable games for manipulation is difficult.  Meanwhile, from a deductive reasoning, the distance between fair actors' preferences $P_i$ and $\mathbf{G(t)}$ should diminish as their rank increases, reflecting the protocol's design of identifying participants alignment.


			This means that for any protocol participant, confidence over group conducting a sybil attack will increase as level of games increase, hence they will be more likely to refuse joining games with such, resulting $$\lim_{i \to \infty} \frac{\mathbb{E}[N_{\text{sybils}}(i)]}{i} = N_{\text{min}}$$ Where $N_{min}$ is amount of peers required to join the game. Hence, a straightforward sybil attack scenario where the attacker attempts to manipulate the protocol by flooding games with multiple sybil accounts may be analyzed.
			Then for an attacker who tries to conduct a sybil attack it would cost
			$$\$R(i) = X_g*N_{min}^i$$ to get rank of level $i$. At the same time, for the agent who is relying on his pure competence and wins each game, same cost would be only $$\$C(i) = X_g*i$$
			In the context of governance power, this allows to draw price relationship between governing competence power that may be put at stake, and total value loked (TVL) at stake: $$TVL << \$C(i)$$


			\subsection{Time constraint}

			As discussed in the previous section, any overt sybil attack requires multiple game rounds to establish a sufficient ranking within the system. In the original protocol, participants engage in several voting and proposing rounds to determine a winner.

			We preserve this multi-round requirement to enhance protocol security, ensuring resistance to centralization and maintaining mission alignment. We introduce a time constraint,  $t_c$ which represents the minimum time needed to mint a single competence asset of any rank.
			Therefore, the intrinsic value of a tokenized competence rating is determined not only by financial effort and success among peers but also by the time invested in continuously improving one's position within the system. Even with parallel attack instances, an attacker would still require $t_{attack}(i) = t_c \cdot i$ time to reach rank $i$. This extended duration allows protocol members ample opportunity to detect and respond to the attack. Similarly, the $t_c$ may be broken down to smaller components, giving participants ability to leave or cancel a game, specify round times etc.


			\subsection{Composable architecture}
			As evidenced by The DAO hack\cite{Liu2021} a single entity governing on-chain operations creates a central point of failure. Even with a theoretically perfect design, a single governing body struggles to match the versatility, adaptability of smaller groups is desired \cite{Buterin22}.  This highlights the necessity of multidimensionality to achieve a robust, global DAO concept while maintaining high performance.

			Composable architecture enables multiple independent DAOs $\mathbf{G}$ to coexist, while free market values encourage convergence when their goals align (section \ref{sec:market-values}). Practically, this means multiple protocol instances $j$, can exist, each with its own initiator, subject, and global alignment vector split in numerous individual pieces that can be expressed as $\mathbf{G_j}$. \\

			A non-permissive rating system can amplify voting power or grant specific permissions within a DAO. A global, distributed DAO emerges as the sum of all $G_j$. Participants gain subject-specific competence $C_{j}$ leading to a subject-specific DAO with governance weights $W_j$ defined solely by competence identification process: $W_j = f(C_{j})$. Since by protocol design $C_j=f(t_c)$, the resulting weights are also function of time $W_j=f(t_c)$\\
			Existing DAO frameworks using fungible tokens fit this model, as their governance token can be derived from $C_{j}$ through a unidirectional asset exchange. Such asset separation creates an exit strategy for high-scoring participants, allowing them to reset their competence score in favor of governance power in the underlying DAO.
			Due to the diminishing number of participants at higher ranks, exponential rewards are necessary to prevent stagnation and incentivize participation. The governance power function must also consider sybil attacks: $P_g = f(C_{j})$ would have to be exponential to ensure proportional rewards with a straightforward sybil attack case: $$P_g(i,j) \propto  X_{g_j}*\mathbb{E}[N_{sybils_j}]^{i_j}$$
			If a group of high-scoring participants exits in such a way, they're likely to gain significant power in the underlying DAO, whose reputation is established from past rounds. This group $V_{aj}$ becomes a practical representation of $G_j(t)$ in DAO form at particular $t$ when they have quorum. We intentionally denote this as function of time as this would not stop the competence minting for other participants. This action also woud not affect already established possible uses for competence rating system with, as if such participant group would even be able to define $G_j(t)$ in favor of their specific subset $V_{aj}$, they would not be able to affect in any means competence systems depending on$C _{i,j}$ due to unidirectional control flow with exception of the fact that these participants $C_{j}$ value is zeroed in favor of DAO governance perspective.
			Nevertheless, such quorum group can dictate policies, acting as a "managerial body" for the specific $G_j$. This group is incentivized to increase the market value of their exchanged governance power, requiring their DAO to generate additional intrinsic value. \\
			The Nakamoto coefficient in such a system increases over time. As the organization gains value, governance power inflation is expected. Early, high-ranking participants can maintain power by strategically purchasing lower-ranking members' $C_{j}$ to prevent others from gaining higher ranks. However, they must remain active to avoid being displaced by inflation and new participants.

			\input{exit.tex}

			A composable DAO framework emerges when a high-scoring group managing a DAO votes to deploy another autonomous competence protocol with a subsidiary DAO, adding both to a new multisignature wallet. This effectively splits the original organization, with asset ownership linked to the original but the Nakamoto coefficient accounting for both governing bodies. The derived protocol participation cost may be derived from parent DAO  $ \grave{X}_{gj}$ to $G_j$, creating a network of interconnected DAOs.

		This composable architecture offers a decentralized, scalable, and adaptable governance model for DAOs. By incorporating competence-based governance and exponential rewards, it fosters a dynamic environment where participants are incentivized to contribute and excel, while mitigating the risks of centralized control and stagnation.


		\subsection{Privacy constraints}

		This paper addresses privacy requirements in a proposal evaluation protocol. The protocol aims to balance transparency and anonymity by:
		\begin{itemize}
			\item Linking Proposals to Proposers: Enabling the association of proposal submissions events with specific proposers, without revealing the proposal content initially.
			\item Verifying Proposal Uniqueness: Ensuring the submitted proposal was uniquely known to the proposer at the time of announcement, while preserving proposer anonymity.
			\item Protecting Preference Selection: Safeguarding the privacy of participant preferences during proposal selection.

		\end{itemize}
		\paragraph{}

		These measures aim to mitigate the Halo effect, where judgments are influenced by personalities rather than ideas, and deter strategic voting by increasing the complexity of coordinated attacks against competent proposals. The de-personalized voting process aims to foster a fairer evaluation environment by focusing on the merit of the proposals themselves.
		% \end{multicols}

		\paragraph{}
		% \begin{multicols}{2}

		Concluding this section, we advocate that multidimensionality and free-market values will provide a way to ensure high participation rates, as participants will be able to participate in the decision-making process in a category that they are interested in, grouping with like-minded people in the fields they are competent in, and lastly - are rewarded for being in.
		With a ranking ladder, and a multidimensional representation, this can be seen as a global framework for building education and helping young talents to discover their path by observing very well quantized data on their progress. \\ We may also suggest that this protocol functionally may be presented as simply a new way of talking, where each input - seen as valuable idea, and each vote - seen as a valuable feedback, and each game final, as actionable result.\\
		In order to support such high participation rates, the user experience must be ensured as simple as possible, and the application must be designed in a way that it is easy to use and understand. In order for that, we require to have extensive metadata available for user experience purpose by the protocol as key requirement. For example, when participant sends in encrypted vote, or proposal - protocol shall be able to publicly announce that particular participant has submitted a vote, while not revealing the content of the vote nor the linkage to it after content is revealed for voting.\\





		% Write your conclusion here
		\section{Implementation}
		Protocol particular implementation may vary depending on environment and requirements, however we can outline a generic implementation that can be used as a reference for further development. Following reference describes implementation as a smart contract on Ethereum Virtual Machine compatible network. \\

	\end{multicols}
	\input{algo}
	\begin{multicols}{2}



		Protocol consists of a semi-fungible tokenized asset contract, such as defined by ERC1155\cite{EIP1155} interface standard and with emission permit granted only to contract or contracts, that implementing autonomous competence identification. Game participation fee for such contracts is pre-defined and may consist of arbitrary asset commitment.
		At this stage, protocol simply produces a competence representation in tokenized mean. The competence identification protocol contracts are turn-based continuous proposing-voting systems. Number of rounds and minimal time to make turns may be fixed to disavow any surprise governance attack. Game Master may be implemented as MPC network that obfuscated signs messages collectively

		which will be either burned, either accumulated in DAO treasury      DAO contract, any typical industry standard implementation may be used; An voting power token


		that allows participants to submit proposals, vote on proposals, and receive rewards based on their participation. Subject representing subject asset can be represented as semi-fungible asset, like standard interface on Ethereum, where each token id represents a rank level, and games that award such rank require a token of one below to be held in order to participate. \\ Such tokenized asset shall be created (minted) only as a result of competence identifying smart contract activity result. The competence identifying contract is a turn-based game where group must collect together and has a signer-key (game master), who is able to sign for a private inputs and keep personalities of participants hidden by either using MPC or zk-SNARKs protocol.
		The game master is responsible for collecting proposals and announcing fact of activity without disclosing the actor, then posting them as batch to a contract, collecting votes in a similar manner, without tell nor who, nor for whom votes, and finally revealing the results.\\



		% Write your results here
		\section{Case Study}
		Some rough statistical data could be gathered by analyzing groups activity and historical records, which show that since 2017 total 17 games were played up to end of 2023. Each averaged for 13 turns, 8 participants and 3 month duration. Total amount of proposals and votes reaching ~1700, as game is stopped at 100 songs playlist length. Total 34 participants joined it over course of years, out from which 22 players completed at least one full tournament and 15 completed at least two full tournaments. From original 6 players 3 still were playing at the moment of writing, with active user count 8 at latest game, showing steady with high user retention. Total amount of players not submitting a vote shown to be negligibly small, below 5\% of all votes. \\
		Even despite absence of any incentives beyond that participants are genuinely interested in the subject, and burden of having to be a game master occasionally which requires participants to do some effort, we can see exceptionally high user participation rates with average:
		\begin{itemize}
			\item participation rate of 95\% for active users
			\item User retention for three month period of 65\%
			\item User retention for two tournaments and roughly six month of 44\%
			\item User retention after 72 month of 9\%
			\item Average of 8 proposals and votes per participant per annum
		\end{itemize}

		The low absolute numbers however are explainable by user complex manual score calculation process and closed community by itself which never oriented itself towards big growth and hence let to do assertion that could be even higher on a well designed automated protocol.

		We also observed that collected playlists, ordered by high-score compositions, are of high quality and form a good representation of participants' preferences, while the winner of the tournament is often a participant that is able not simply propose a popular song, but to propose a song that is liked by many participants, including such aspects that participants will likely vote songs they hear for the first time (original ideas).

		\subsection{Governance integration}
		In already established DAOs, this mechanism may be used to define slashing conditions. For example, a participant may have a right to perform privileged action on a DAO, by locking his competence level in escrow contract. If later, DAO votes with majority quorum condemning such an action as adversarial to the protocol, it may burn competence token of such an actor, which would result to have associated losses equal to cost of obtaining that competence asset. As per previous section, we've seen that such relationships may be reasoned.

		For a broad and generic case, however, protocol use is envisioned to be able to bootstrap decentralized organizations, acting as replacement for initial-coin offerings \cite{Alshater22} and airdrops popular in DAOs today. In this, a DAO bootstrapped by competence identification protocol creates own intrinsic value on the go, the long sustained participation with participation high participation rates may result in DAO led decisions to deploy infrastructure or elaborate any protocol that would embed intrinsic value to such.

		This also seems like a very natural way for autonomous organizations to scale from security standpoint, as if any quorum, sybil attack and others



		\section{Conclusion}

		we are generalizing the proof based consensus mechanisms for social network interaction by viewing any network node as rational-agent which may diverge from collective interest \cite{Philip2019} individually or collude with others. We propose BFT tolerance methodology that allows reaching effective consensus based on participant inputs, opinions and  we can say that protocols reach an agreement in a trustless environment by qualifying the competence of the participants. Bitcoin miners are required to solve a cryptographic puzzle to prove their competence, or ethereum Proof of Stake consensus mechanism qualifies participants by their ability by ability to adhere to distributed ledger rules a   nd stake their assets. \\ Similarly DAO participants are qualified by their ability to hold a token and participate in the voting process. Tokens held can be seen as analogy to stake in PoS consensus mechanism, incentivising participants to act in the best interest of the organization. The gap however exists between such automated protocols and DAO governance as organizations agenda may be much more arguable then a "simple" cryptographic puzzle, which despite any computational complexity it might have, most of the time can be formally verified to be correct.\\
		This becomes more emergent as the DAOs are becoming more complex and must take effective and prompt decisions in a trustless environment, which often leads to burden of complexity on users, while often a decision making process involves a fairly traditional board-level discussions within governance forum boards, which yields for doubts as researchers find blockchain-based governance systems likely not to solve problems of social.

		The contrast between traditional organization and blockchain is that latter are set to follow some determined protocol of following consensus layer decisions in an autonomous way, therefore enabling CPS, there is no need for human stakeholder decision for a regular operations which are automated by running specific software applications (nodes) that maintain protocol on behalf of stakeholder.
		These however work only well up to the point when the protocol changes are desired or some vulnerability happens which leads to need for stepping-off the protocol rules for at least one block. Such occasions generally are called hard-forks and have specifics that coordinated consensus between node operators changes their protocol rules to move away from existing logic. The "fork" in context describes split of consensus in two possible ledger book states which are not compatible.\
	\end{multicols}
	\bibliographystyle{ieeetr}
	\bibliography{whitepaper.bib}

	\clearpage\end{CJK}
\end{document}